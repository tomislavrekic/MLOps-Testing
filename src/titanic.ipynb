{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///../mlflow.db\")\n",
    "      \n",
    "client = mlflow.tracking.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../data/titanic/\"\n",
    "train_df = pd.read_csv(os.path.join(dataset_path, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(dataset_path, \"test.csv\"))\n",
    "\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age       86\n",
      "Fare       1\n",
      "Cabin    327\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nullseries = test_df.isnull().sum()\n",
    "print(nullseries[nullseries > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_459683/171630453.py:4: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(survived_males['Embarked'], color='g', bins=100, hist_kws={'alpha': 0.4})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/media/tomislav/023ABC973ABC8965/Projekti/MLOps-Testing/src/titanic.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/tomislav/023ABC973ABC8965/Projekti/MLOps-Testing/src/titanic.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m survived_males \u001b[39m=\u001b[39m train_df[(train_df[\u001b[39m'\u001b[39m\u001b[39mSurvived\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/tomislav/023ABC973ABC8965/Projekti/MLOps-Testing/src/titanic.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#survived_males.head(3)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/tomislav/023ABC973ABC8965/Projekti/MLOps-Testing/src/titanic.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sns\u001b[39m.\u001b[39;49mdistplot(survived_males[\u001b[39m'\u001b[39;49m\u001b[39mEmbarked\u001b[39;49m\u001b[39m'\u001b[39;49m], color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mg\u001b[39;49m\u001b[39m'\u001b[39;49m, bins\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, hist_kws\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39malpha\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0.4\u001b[39;49m})\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/titanic_env/lib/python3.11/site-packages/seaborn/distributions.py:2458\u001b[0m, in \u001b[0;36mdistplot\u001b[0;34m(a, bins, hist, kde, rug, fit, hist_kws, kde_kws, rug_kws, fit_kws, color, vertical, norm_hist, axlabel, label, ax, x)\u001b[0m\n\u001b[1;32m   2455\u001b[0m     a \u001b[39m=\u001b[39m x\n\u001b[1;32m   2457\u001b[0m \u001b[39m# Make a a 1-d float array\u001b[39;00m\n\u001b[0;32m-> 2458\u001b[0m a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(a, \u001b[39mfloat\u001b[39;49m)\n\u001b[1;32m   2459\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2460\u001b[0m     a \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/titanic_env/lib/python3.11/site-packages/pandas/core/series.py:953\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[39mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[39m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    952\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m--> 953\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(values, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    954\u001b[0m \u001b[39mif\u001b[39;00m using_copy_on_write() \u001b[39mand\u001b[39;00m astype_is_view(values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m    955\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'C'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvgAAAKZCAYAAADNil8cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjO0lEQVR4nO3df2zV9b348Veh0Kr3toswKwiysqsbG5m7lMAolyzzag0aF5LdyOKNqFeTNdsuQq/ewbjRQUya7Wbmzk1wm6BZgo74M/7R6+gf9yIK9wfcsiyDxEW4FrZWUowt6m4R+Nw//NLv7VqEU/trLx6P5Pxx3nu/T99nea95+vHTz8qKoigCAABIYcJYbwAAABg+Ah8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASKTnwX3755bj55ptj+vTpUVZWFi+88MI51+zYsSPq6uqisrIyZs+eHY8++uhQ9goAAJxDyYH/7rvvxjXXXBM/+tGPzmv+oUOH4sYbb4wlS5ZEW1tbfPvb346VK1fGs88+W/JmAQCAD1dWFEUx5MVlZfH888/HsmXLzjrnW9/6Vrz44otx4MCBvrHGxsb45S9/Gbt37x7qjwYAAAZRPtI/YPfu3dHQ0NBv7IYbbojNmzfH+++/H5MmTRqwpre3N3p7e/venz59Ot56662YMmVKlJWVjfSWAQBgxBVFEcePH4/p06fHhAnD96exIx74nZ2dUVNT02+spqYmTp48GV1dXTFt2rQBa5qbm2P9+vUjvTUAABhzhw8fjhkzZgzb54144EfEgKvuZ+4KOtvV+LVr10ZTU1Pf++7u7rjyyivj8OHDUVVVNXIbBQCAUdLT0xMzZ86MP/3TPx3Wzx3xwL/88sujs7Oz39jRo0ejvLw8pkyZMuiaioqKqKioGDBeVVUl8AEASGW4b0Ef8efgL1q0KFpbW/uNbd++PebPnz/o/fcAAMDQlRz477zzTuzbty/27dsXER88BnPfvn3R3t4eER/cXrNixYq++Y2NjfHGG29EU1NTHDhwILZs2RKbN2+Oe++9d3i+AQAA0KfkW3T27NkTX/rSl/ren7lX/vbbb48nnngiOjo6+mI/IqK2tjZaWlpi9erV8cgjj8T06dPj4Ycfjq985SvDsH0AAOD/+kjPwR8tPT09UV1dHd3d3e7BBwAghZFq3BG/Bx8AABg9Ah8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhkSIG/cePGqK2tjcrKyqirq4udO3d+6PytW7fGNddcExdffHFMmzYt7rzzzjh27NiQNgwAAJxdyYG/bdu2WLVqVaxbty7a2tpiyZIlsXTp0mhvbx90/iuvvBIrVqyIu+66K37961/H008/Hf/5n/8Zd99990fePAAA0F/Jgf/QQw/FXXfdFXfffXfMmTMn/umf/ilmzpwZmzZtGnT+v/3bv8UnPvGJWLlyZdTW1sZf/MVfxNe+9rXYs2fPR948AADQX0mBf+LEidi7d280NDT0G29oaIhdu3YNuqa+vj6OHDkSLS0tURRFvPnmm/HMM8/ETTfddNaf09vbGz09Pf1eAADAuZUU+F1dXXHq1KmoqanpN15TUxOdnZ2Drqmvr4+tW7fG8uXLY/LkyXH55ZfHxz72sfjhD3941p/T3Nwc1dXVfa+ZM2eWsk0AALhgDemPbMvKyvq9L4piwNgZ+/fvj5UrV8b9998fe/fujZdeeikOHToUjY2NZ/38tWvXRnd3d9/r8OHDQ9kmAABccMpLmTx16tSYOHHigKv1R48eHXBV/4zm5uZYvHhx3HfffRER8bnPfS4uueSSWLJkSTz44IMxbdq0AWsqKiqioqKilK0BAABR4hX8yZMnR11dXbS2tvYbb21tjfr6+kHXvPfeezFhQv8fM3HixIj44Mo/AAAwfEq+RaepqSkee+yx2LJlSxw4cCBWr14d7e3tfbfcrF27NlasWNE3/+abb47nnnsuNm3aFAcPHoxXX301Vq5cGQsWLIjp06cP3zcBAABKu0UnImL58uVx7Nix2LBhQ3R0dMTcuXOjpaUlZs2aFRERHR0d/Z6Jf8cdd8Tx48fjRz/6Ufzd3/1dfOxjH4trr702vvvd7w7ftwAAACIioqz4I7hPpqenJ6qrq6O7uzuqqqrGejsAAPCRjVTjDukpOgAAwPgk8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgESGFPgbN26M2traqKysjLq6uti5c+eHzu/t7Y1169bFrFmzoqKiIj75yU/Gli1bhrRhAADg7MpLXbBt27ZYtWpVbNy4MRYvXhw//vGPY+nSpbF///648sorB11zyy23xJtvvhmbN2+OP/uzP4ujR4/GyZMnP/LmAQCA/sqKoihKWbBw4cKYN29ebNq0qW9szpw5sWzZsmhubh4w/6WXXoqvfvWrcfDgwbj00kuHtMmenp6orq6O7u7uqKqqGtJnAADAeDJSjVvSLTonTpyIvXv3RkNDQ7/xhoaG2LVr16BrXnzxxZg/f35873vfiyuuuCKuvvrquPfee+P3v//90HcNAAAMqqRbdLq6uuLUqVNRU1PTb7ympiY6OzsHXXPw4MF45ZVXorKyMp5//vno6uqKr3/96/HWW2+d9T783t7e6O3t7Xvf09NTyjYBAOCCNaQ/si0rK+v3viiKAWNnnD59OsrKymLr1q2xYMGCuPHGG+Ohhx6KJ5544qxX8Zubm6O6urrvNXPmzKFsEwAALjglBf7UqVNj4sSJA67WHz16dMBV/TOmTZsWV1xxRVRXV/eNzZkzJ4qiiCNHjgy6Zu3atdHd3d33Onz4cCnbBACAC1ZJgT958uSoq6uL1tbWfuOtra1RX18/6JrFixfH7373u3jnnXf6xl577bWYMGFCzJgxY9A1FRUVUVVV1e8FAACcW8m36DQ1NcVjjz0WW7ZsiQMHDsTq1aujvb09GhsbI+KDq+8rVqzom3/rrbfGlClT4s4774z9+/fHyy+/HPfdd1/8zd/8TVx00UXD900AAIDSn4O/fPnyOHbsWGzYsCE6Ojpi7ty50dLSErNmzYqIiI6Ojmhvb++b/yd/8ifR2toaf/u3fxvz58+PKVOmxC233BIPPvjg8H0LAAAgIobwHPyx4Dn4AABkMy6egw8AAIxvAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCJDCvyNGzdGbW1tVFZWRl1dXezcufO81r366qtRXl4en//854fyYwEAgHMoOfC3bdsWq1atinXr1kVbW1ssWbIkli5dGu3t7R+6rru7O1asWBF/+Zd/OeTNAgAAH66sKIqilAULFy6MefPmxaZNm/rG5syZE8uWLYvm5uazrvvqV78aV111VUycODFeeOGF2Ldv33n/zJ6enqiuro7u7u6oqqoqZbsAADAujVTjlnQF/8SJE7F3795oaGjoN97Q0BC7du0667rHH388Xn/99XjggQfO6+f09vZGT09PvxcAAHBuJQV+V1dXnDp1KmpqavqN19TURGdn56BrfvOb38SaNWti69atUV5efl4/p7m5Oaqrq/teM2fOLGWbAABwwRrSH9mWlZX1e18UxYCxiIhTp07FrbfeGuvXr4+rr776vD9/7dq10d3d3fc6fPjwULYJAAAXnPO7pP7/TJ06NSZOnDjgav3Ro0cHXNWPiDh+/Hjs2bMn2tra4pvf/GZERJw+fTqKoojy8vLYvn17XHvttQPWVVRUREVFRSlbAwAAosQr+JMnT466urpobW3tN97a2hr19fUD5ldVVcWvfvWr2LdvX9+rsbExPvWpT8W+ffti4cKFH233AABAPyVdwY+IaGpqittuuy3mz58fixYtip/85CfR3t4ejY2NEfHB7TW//e1v42c/+1lMmDAh5s6d22/9ZZddFpWVlQPGAQCAj67kwF++fHkcO3YsNmzYEB0dHTF37txoaWmJWbNmRURER0fHOZ+JDwAAjIySn4M/FjwHHwCAbMbFc/ABAIDxTeADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJDCnwN27cGLW1tVFZWRl1dXWxc+fOs8597rnn4vrrr4+Pf/zjUVVVFYsWLYpf/OIXQ94wAABwdiUH/rZt22LVqlWxbt26aGtriyVLlsTSpUujvb190Pkvv/xyXH/99dHS0hJ79+6NL33pS3HzzTdHW1vbR948AADQX1lRFEUpCxYuXBjz5s2LTZs29Y3NmTMnli1bFs3Nzef1GZ/97Gdj+fLlcf/995/X/J6enqiuro7u7u6oqqoqZbsAADAujVTjlnQF/8SJE7F3795oaGjoN97Q0BC7du06r884ffp0HD9+PC699NKzzunt7Y2enp5+LwAA4NxKCvyurq44depU1NTU9BuvqamJzs7O8/qM73//+/Huu+/GLbfcctY5zc3NUV1d3feaOXNmKdsEAIAL1pD+yLasrKzf+6IoBowN5qmnnorvfOc7sW3btrjsssvOOm/t2rXR3d3d9zp8+PBQtgkAABec8lImT506NSZOnDjgav3Ro0cHXNX/Q9u2bYu77rornn766bjuuus+dG5FRUVUVFSUsjUAACBKvII/efLkqKuri9bW1n7jra2tUV9ff9Z1Tz31VNxxxx3x5JNPxk033TS0nQIAAOdU0hX8iIimpqa47bbbYv78+bFo0aL4yU9+Eu3t7dHY2BgRH9xe89vf/jZ+9rOfRcQHcb9ixYr4wQ9+EF/4whf6rv5fdNFFUV1dPYxfBQAAKDnwly9fHseOHYsNGzZER0dHzJ07N1paWmLWrFkREdHR0dHvmfg//vGP4+TJk/GNb3wjvvGNb/SN33777fHEE0989G8AAAD0Kfk5+GPBc/ABAMhmXDwHHwAAGN8EPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJCIwAcAgEQEPgAAJCLwAQAgEYEPAACJCHwAAEhE4AMAQCICHwAAEhH4AACQiMAHAIBEBD4AACQi8AEAIBGBDwAAiQh8AABIROADAEAiAh8AABIR+AAAkMiQAn/jxo1RW1sblZWVUVdXFzt37vzQ+Tt27Ii6urqorKyM2bNnx6OPPjqkzQIAAB+u5MDftm1brFq1KtatWxdtbW2xZMmSWLp0abS3tw86/9ChQ3HjjTfGkiVLoq2tLb797W/HypUr49lnn/3ImwcAAPorK4qiKGXBwoULY968ebFp06a+sTlz5sSyZcuiubl5wPxvfetb8eKLL8aBAwf6xhobG+OXv/xl7N69+7x+Zk9PT1RXV0d3d3dUVVWVsl0AABiXRqpxy0uZfOLEidi7d2+sWbOm33hDQ0Ps2rVr0DW7d++OhoaGfmM33HBDbN68Od5///2YNGnSgDW9vb3R29vb9767uzsiPvgvAQAAMjjTtiVebz+nkgK/q6srTp06FTU1Nf3Ga2pqorOzc9A1nZ2dg84/efJkdHV1xbRp0wasaW5ujvXr1w8YnzlzZinbBQCAce/YsWNRXV09bJ9XUuCfUVZW1u99URQDxs41f7DxM9auXRtNTU19799+++2YNWtWtLe3D+uXJ5+enp6YOXNmHD582O1cnJPzwvlyViiF88L56u7ujiuvvDIuvfTSYf3ckgJ/6tSpMXHixAFX648ePTrgKv0Zl19++aDzy8vLY8qUKYOuqaioiIqKigHj1dXV/ofCeamqqnJWOG/OC+fLWaEUzgvna8KE4X1yfUmfNnny5Kirq4vW1tZ+462trVFfXz/omkWLFg2Yv3379pg/f/6g998DAABDV/I/LjQ1NcVjjz0WW7ZsiQMHDsTq1aujvb09GhsbI+KD22tWrFjRN7+xsTHeeOONaGpqigMHDsSWLVti8+bNce+99w7ftwAAACJiCPfgL1++PI4dOxYbNmyIjo6OmDt3brS0tMSsWbMiIqKjo6PfM/Fra2ujpaUlVq9eHY888khMnz49Hn744fjKV75y3j+zoqIiHnjggUFv24H/y1mhFM4L58tZoRTOC+drpM5Kyc/BBwAAxq/hvaMfAAAYUwIfAAASEfgAAJCIwAcAgETGTeBv3Lgxamtro7KyMurq6mLnzp0fOn/Hjh1RV1cXlZWVMXv27Hj00UdHaaeMtVLOynPPPRfXX399fPzjH4+qqqpYtGhR/OIXvxjF3TLWSv3dcsarr74a5eXl8fnPf35kN8i4UepZ6e3tjXXr1sWsWbOioqIiPvnJT8aWLVtGabeMtVLPy9atW+Oaa66Jiy++OKZNmxZ33nlnHDt2bJR2y1h5+eWX4+abb47p06dHWVlZvPDCC+dcMyyNW4wDP//5z4tJkyYVP/3pT4v9+/cX99xzT3HJJZcUb7zxxqDzDx48WFx88cXFPffcU+zfv7/46U9/WkyaNKl45plnRnnnjLZSz8o999xTfPe73y3+4z/+o3jttdeKtWvXFpMmTSr+67/+a5R3zlgo9byc8fbbbxezZ88uGhoaimuuuWZ0NsuYGspZ+fKXv1wsXLiwaG1tLQ4dOlT8+7//e/Hqq6+O4q4ZK6Wel507dxYTJkwofvCDHxQHDx4sdu7cWXz2s58tli1bNso7Z7S1tLQU69atK5599tkiIornn3/+Q+cPV+OOi8BfsGBB0djY2G/s05/+dLFmzZpB5//93/998elPf7rf2Ne+9rXiC1/4wojtkfGh1LMymM985jPF+vXrh3trjENDPS/Lly8v/uEf/qF44IEHBP4FotSz8s///M9FdXV1cezYsdHYHuNMqeflH//xH4vZs2f3G3v44YeLGTNmjNgeGX/OJ/CHq3HH/BadEydOxN69e6OhoaHfeENDQ+zatWvQNbt37x4w/4Ybbog9e/bE+++/P2J7ZWwN5az8odOnT8fx48fj0ksvHYktMo4M9bw8/vjj8frrr8cDDzww0ltknBjKWXnxxRdj/vz58b3vfS+uuOKKuPrqq+Pee++N3//+96OxZcbQUM5LfX19HDlyJFpaWqIoinjzzTfjmWeeiZtuumk0tswfkeFq3JL/n2yHW1dXV5w6dSpqamr6jdfU1ERnZ+egazo7Owedf/Lkyejq6opp06aN2H4ZO0M5K3/o+9//frz77rtxyy23jMQWGUeGcl5+85vfxJo1a2Lnzp1RXj7mvx4ZJUM5KwcPHoxXXnklKisr4/nnn4+urq74+te/Hm+99Zb78JMbynmpr6+PrVu3xvLly+N//ud/4uTJk/HlL385fvjDH47GlvkjMlyNO+ZX8M8oKyvr974oigFj55o/2Dj5lHpWznjqqafiO9/5Tmzbti0uu+yykdoe48z5npdTp07FrbfeGuvXr4+rr756tLbHOFLK75bTp09HWVlZbN26NRYsWBA33nhjPPTQQ/HEE0+4in+BKOW87N+/P1auXBn3339/7N27N1566aU4dOhQNDY2jsZW+SMzHI075peopk6dGhMnThzwT71Hjx4d8E8wZ1x++eWDzi8vL48pU6aM2F4ZW0M5K2ds27Yt7rrrrnj66afjuuuuG8ltMk6Uel6OHz8ee/bsiba2tvjmN78ZER9EXFEUUV5eHtu3b49rr712VPbO6BrK75Zp06bFFVdcEdXV1X1jc+bMiaIo4siRI3HVVVeN6J4ZO0M5L83NzbF48eK47777IiLic5/7XFxyySWxZMmSePDBB915QJ/hatwxv4I/efLkqKuri9bW1n7jra2tUV9fP+iaRYsWDZi/ffv2mD9/fkyaNGnE9srYGspZifjgyv0dd9wRTz75pPsdLyClnpeqqqr41a9+Ffv27et7NTY2xqc+9anYt29fLFy4cLS2zigbyu+WxYsXx+9+97t45513+sZee+21mDBhQsyYMWNE98vYGsp5ee+992LChP7JNXHixIj4/1dnIWIYG7ekP8kdIWceN7V58+Zi//79xapVq4pLLrmk+O///u+iKIpizZo1xW233dY3/8wjhFavXl3s37+/2Lx5s8dkXiBKPStPPvlkUV5eXjzyyCNFR0dH3+vtt98eq6/AKCr1vPwhT9G5cJR6Vo4fP17MmDGj+Ku/+qvi17/+dbFjx47iqquuKu6+++6x+gqMolLPy+OPP16Ul5cXGzduLF5//fXilVdeKebPn18sWLBgrL4Co+T48eNFW1tb0dbWVkRE8dBDDxVtbW19j1QdqcYdF4FfFEXxyCOPFLNmzSomT55czJs3r9ixY0fff3b77bcXX/ziF/vN/9d//dfiz//8z4vJkycXn/jEJ4pNmzaN8o4ZK6WclS9+8YtFRAx43X777aO/ccZEqb9b/i+Bf2Ep9awcOHCguO6664qLLrqomDFjRtHU1FS89957o7xrxkqp5+Xhhx8uPvOZzxQXXXRRMW3atOKv//qviyNHjozyrhlt//Iv//KhHTJSjVtWFP7dEAAAZDHm9+ADAADDR+ADAEAiAh8AABIR+AAAkIjABwCARAQ+AAAkIvABACARgQ8AAIkIfAAASETgAwBAIgIfAAASEfgAAJDI/wLZpp7JR+QHVwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 900x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 8))\n",
    "survived_males = train_df[(train_df['Survived'] == 1) & (train_df['Embarked'] == \"male\")]\n",
    "#survived_males.head(3)\n",
    "sns.distplot(survived_males['Pclass'], color='g', bins=100, hist_kws={'alpha': 0.4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       " Mr              517\n",
       " Miss            182\n",
       " Mrs             125\n",
       " Master           40\n",
       " Dr                7\n",
       " Rev               6\n",
       " Mlle              2\n",
       " Major             2\n",
       " Col               2\n",
       " the Countess      1\n",
       " Capt              1\n",
       " Ms                1\n",
       " Sir               1\n",
       " Lady              1\n",
       " Mme               1\n",
       " Don               1\n",
       " Jonkheer          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['Last_name', 'First_name']] = train_df['Name'].str.split(',', n=1, expand=True) \n",
    "train_df['Title'] = train_df['Name'].map(lambda x: x.split(',')[1].split('.')[0])\n",
    "train_df['Title'].value_counts()\n",
    "#train_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>31.025000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>27.720800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>49.168457</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>39.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>48.500000</td>\n",
       "      <td>28.525000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>4.574167</td>\n",
       "      <td>34.703125</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>21.773973</td>\n",
       "      <td>43.797873</td>\n",
       "      <td>0.697802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>59.402100</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>69.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>32.368090</td>\n",
       "      <td>24.441560</td>\n",
       "      <td>0.156673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>35.898148</td>\n",
       "      <td>45.138533</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>43.166667</td>\n",
       "      <td>18.312500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>56.929200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the Countess</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Age       Fare  Survived\n",
       "Title                                        \n",
       " Capt          70.000000  71.000000  0.000000\n",
       " Col           58.000000  31.025000  0.500000\n",
       " Don           40.000000  27.720800  0.000000\n",
       " Dr            42.000000  49.168457  0.428571\n",
       " Jonkheer      38.000000   0.000000  0.000000\n",
       " Lady          48.000000  39.600000  1.000000\n",
       " Major         48.500000  28.525000  0.500000\n",
       " Master         4.574167  34.703125  0.575000\n",
       " Miss          21.773973  43.797873  0.697802\n",
       " Mlle          24.000000  59.402100  1.000000\n",
       " Mme           24.000000  69.300000  1.000000\n",
       " Mr            32.368090  24.441560  0.156673\n",
       " Mrs           35.898148  45.138533  0.792000\n",
       " Ms            28.000000  13.000000  1.000000\n",
       " Rev           43.166667  18.312500  0.000000\n",
       " Sir           49.000000  56.929200  1.000000\n",
       " the Countess  33.000000  86.500000  1.000000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_df[['Title', 'Age', 'Fare', 'Survived']].groupby('Title').mean()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Last_name</th>\n",
       "      <th>First_name</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Braund</td>\n",
       "      <td>Mr. Owen Harris</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>Miss. Laina</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  Last_name  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S     Braund   \n",
       "1      0          PC 17599  71.2833   C85        C    Cumings   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  Heikkinen   \n",
       "\n",
       "                                    First_name  Title  \n",
       "0                              Mr. Owen Harris     Mr  \n",
       "1   Mrs. John Bradley (Florence Briggs Thayer)    Mrs  \n",
       "2                                  Miss. Laina   Miss  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId  Survived  Pclass  Name                                                      Sex     Age    SibSp  Parch  Ticket             Fare      Cabin        Embarked  Last_name               First_name                                         Title        \n",
       "4            1         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)              female  35.00  1      0      113803             53.1000   C123         S         Futrelle                 Mrs. Jacques Heath (Lily May Peel)                 Mrs             1\n",
       "718          1         2       Troutt, Miss. Edwina Celia \"Winnie\"                       female  27.00  0      0      34218              10.5000   E101         S         Troutt                   Miss. Edwina Celia \"Winnie\"                        Miss            1\n",
       "708          1         1       Calderhead, Mr. Edward Pennington                         male    42.00  0      0      PC 17476           26.2875   E24          S         Calderhead               Mr. Edward Pennington                              Mr              1\n",
       "702          1         1       Silverthorne, Mr. Spencer Victor                          male    35.00  0      0      PC 17475           26.2875   E24          S         Silverthorne             Mr. Spencer Victor                                 Mr              1\n",
       "691          1         1       Dick, Mr. Albert Adrian                                   male    31.00  1      0      17474              57.0000   B20          S         Dick                     Mr. Albert Adrian                                  Mr              1\n",
       "690          1         1       Madill, Miss. Georgette Alexandra                         female  15.00  0      1      24160              211.3375  B5           S         Madill                   Miss. Georgette Alexandra                          Miss            1\n",
       "631          1         1       Barkworth, Mr. Algernon Henry Wilson                      male    80.00  0      0      27042              30.0000   A23          S         Barkworth                Mr. Algernon Henry Wilson                          Mr              1\n",
       "628          1         1       Longley, Miss. Gretchen Fiske                             female  21.00  0      0      13502              77.9583   D9           S         Longley                  Miss. Gretchen Fiske                               Miss            1\n",
       "622          1         1       Kimball, Mr. Edwin Nelson Jr                              male    42.00  1      0      11753              52.5542   D19          S         Kimball                  Mr. Edwin Nelson Jr                                Mr              1\n",
       "619          1         2       Becker, Miss. Marion Louise                               female  4.00   2      1      230136             39.0000   F4           S         Becker                   Miss. Marion Louise                                Miss            1\n",
       "610          1         1       Shutes, Miss. Elizabeth W                                 female  40.00  0      0      PC 17582           153.4625  C125         S         Shutes                   Miss. Elizabeth W                                  Miss            1\n",
       "586          1         1       Taussig, Miss. Ruth                                       female  18.00  0      2      110413             79.6500   E68          S         Taussig                  Miss. Ruth                                         Miss            1\n",
       "578          1         1       Silvey, Mrs. William Baird (Alice Munger)                 female  39.00  1      0      13507              55.9000   E44          S         Silvey                   Mrs. William Baird (Alice Munger)                  Mrs             1\n",
       "573          1         1       Flynn, Mr. John Irwin (\"Irving\")                          male    36.00  0      0      PC 17474           26.3875   E25          S         Flynn                    Mr. John Irwin (\"Irving\")                          Mr              1\n",
       "572          1         1       Appleton, Mrs. Edward Dale (Charlotte Lamson)             female  53.00  2      0      11769              51.4792   C101         S         Appleton                 Mrs. Edward Dale (Charlotte Lamson)                Mrs             1\n",
       "559          1         1       Taussig, Mrs. Emil (Tillie Mandelbaum)                    female  39.00  1      1      110413             79.6500   E67          S         Taussig                  Mrs. Emil (Tillie Mandelbaum)                      Mrs             1\n",
       "541          1         1       Crosby, Miss. Harriet R                                   female  36.00  0      2      WE/P 5735          71.0000   B22          S         Crosby                   Miss. Harriet R                                    Miss            1\n",
       "713          1         1       Taylor, Mr. Elmer Zebley                                  male    48.00  1      0      19996              52.0000   C126         S         Taylor                   Mr. Elmer Zebley                                   Mr              1\n",
       "725          1         1       Chambers, Mr. Norman Campbell                             male    27.00  1      0      113806             53.1000   E8           S         Chambers                 Mr. Norman Campbell                                Mr              1\n",
       "11           1         3       Sandstrom, Miss. Marguerite Rut                           female  4.00   1      1      PP 9549            16.7000   G6           S         Sandstrom                Miss. Marguerite Rut                               Miss            1\n",
       "731          1         1       Allen, Miss. Elisabeth Walton                             female  29.00  0      0      24160              211.3375  B5           S         Allen                    Miss. Elisabeth Walton                             Miss            1\n",
       "872          1         1       Beckwith, Mrs. Richard Leonard (Sallie Monypeny)          female  47.00  1      1      11751              52.5542   D35          S         Beckwith                 Mrs. Richard Leonard (Sallie Monypeny)             Mrs             1\n",
       "863          1         1       Swift, Mrs. Frederick Joel (Margaret Welles Barron)       female  48.00  0      0      17466              25.9292   D17          S         Swift                    Mrs. Frederick Joel (Margaret Welles Barron)       Mrs             1\n",
       "858          1         1       Daly, Mr. Peter Denis                                     male    51.00  0      0      113055             26.5500   E17          S         Daly                     Mr. Peter Denis                                    Mr              1\n",
       "854          1         1       Lines, Miss. Mary Conover                                 female  16.00  0      1      PC 17592           39.4000   D28          S         Lines                    Miss. Mary Conover                                 Miss            1\n",
       "824          1         3       Moor, Mrs. (Beila)                                        female  27.00  0      1      392096             12.4750   E121         S         Moor                     Mrs. (Beila)                                       Mrs             1\n",
       "821          1         1       Hays, Mrs. Charles Melville (Clara Jennings Gregg)        female  52.00  1      1      12749              93.5000   B69          S         Hays                     Mrs. Charles Melville (Clara Jennings Gregg)       Mrs             1\n",
       "810          1         1       Chambers, Mrs. Norman Campbell (Bertha Griggs)            female  33.00  1      0      113806             53.1000   E8           S         Chambers                 Mrs. Norman Campbell (Bertha Griggs)               Mrs             1\n",
       "803          1         1       Carter, Master. William Thornton II                       male    11.00  1      2      113760             120.0000  B96 B98      S         Carter                   Master. William Thornton II                        Master          1\n",
       "797          1         1       Leader, Dr. Alice (Farnham)                               female  49.00  0      0      17465              25.9292   D17          S         Leader                   Dr. Alice (Farnham)                                Dr              1\n",
       "782          1         1       Dick, Mrs. Albert Adrian (Vera Gillespie)                 female  17.00  1      0      17474              57.0000   B20          S         Dick                     Mrs. Albert Adrian (Vera Gillespie)                Mrs             1\n",
       "780          1         1       Robert, Mrs. Edward Scott (Elisabeth Walton McMillan)     female  43.00  0      1      24160              211.3375  B3           S         Robert                   Mrs. Edward Scott (Elisabeth Walton McMillan)      Mrs             1\n",
       "766          1         1       Hogeboom, Mrs. John C (Anna Andrews)                      female  51.00  1      0      13502              77.9583   D11          S         Hogeboom                 Mrs. John C (Anna Andrews)                         Mrs             1\n",
       "764          1         1       Carter, Mrs. William Ernest (Lucile Polk)                 female  36.00  1      2      113760             120.0000  B96 B98      S         Carter                   Mrs. William Ernest (Lucile Polk)                  Mrs             1\n",
       "760          1         1       Rothes, the Countess. of (Lucy Noel Martha Dyer-Edwards)  female  33.00  0      0      110152             86.5000   B77          S         Rothes                   the Countess. of (Lucy Noel Martha Dyer-Edwards)   the Countess    1\n",
       "752          1         3       Moor, Master. Meier                                       male    6.00   0      1      392096             12.4750   E121         S         Moor                     Master. Meier                                      Master          1\n",
       "521          1         1       Perreault, Miss. Anne                                     female  30.00  0      0      12749              93.5000   B73          S         Perreault                Miss. Anne                                         Miss            1\n",
       "517          1         2       Lemore, Mrs. (Amelia Milley)                              female  34.00  0      0      C.A. 34260         10.5000   F33          S         Lemore                   Mrs. (Amelia Milley)                               Mrs             1\n",
       "513          1         1       McGough, Mr. James Robert                                 male    36.00  0      0      PC 17473           26.2875   E25          S         McGough                  Mr. James Robert                                   Mr              1\n",
       "505          1         1       Maioni, Miss. Roberta                                     female  16.00  0      0      110152             86.5000   B79          S         Maioni                   Miss. Roberta                                      Miss            1\n",
       "269          1         1       Graham, Mrs. William Thompson (Edith Junkins)             female  58.00  0      1      PC 17582           153.4625  C125         S         Graham                   Mrs. William Thompson (Edith Junkins)              Mrs             1\n",
       "258          1         1       Cherry, Miss. Gladys                                      female  30.00  0      0      110152             86.5000   B77          S         Cherry                   Miss. Gladys                                       Miss            1\n",
       "249          1         1       Beckwith, Mr. Richard Leonard                             male    37.00  1      1      11751              52.5542   D35          S         Beckwith                 Mr. Richard Leonard                                Mr              1\n",
       "231          1         1       Harris, Mrs. Henry Birkhardt (Irene Wallach)              female  35.00  1      0      36973              83.4750   C83          S         Harris                   Mrs. Henry Birkhardt (Irene Wallach)               Mrs             1\n",
       "225          1         1       Hoyt, Mr. Frederick Maxfield                              male    38.00  1      0      19943              90.0000   C93          S         Hoyt                     Mr. Frederick Maxfield                             Mr              1\n",
       "194          1         2       Navratil, Master. Michel M                                male    3.00   1      1      230080             26.0000   F2           S         Navratil                 Master. Michel M                                   Master          1\n",
       "184          1         2       Becker, Master. Richard F                                 male    1.00   2      1      230136             39.0000   F4           S         Becker                   Master. Richard F                                  Master          1\n",
       "152          1         1       Pears, Mrs. Thomas (Edith Wearne)                         female  22.00  1      0      113776             66.6000   C2           S         Pears                    Mrs. Thomas (Edith Wearne)                         Mrs             1\n",
       "137          1         1       Newsom, Miss. Helen Monypeny                              female  19.00  0      2      11752              26.2833   D47          S         Newsom                   Miss. Helen Monypeny                               Miss            1\n",
       "124          1         2       Webber, Miss. Susan                                       female  32.50  0      0      27267              13.0000   E101         S         Webber                   Miss. Susan                                        Miss            1\n",
       "89           1         1       Fortune, Miss. Mabel Helen                                female  23.00  3      2      19950              263.0000  C23 C25 C27  S         Fortune                  Miss. Mabel Helen                                  Miss            1\n",
       "67           1         2       Nye, Mrs. (Elizabeth Ramell)                              female  29.00  0      0      C.A. 29395         10.5000   F33          S         Nye                      Mrs. (Elizabeth Ramell)                            Mrs             1\n",
       "24           1         1       Sloper, Mr. William Thompson                              male    28.00  0      0      113788             35.5000   A6           S         Sloper                   Mr. William Thompson                               Mr              1\n",
       "22           1         2       Beesley, Mr. Lawrence                                     male    34.00  0      0      248698             13.0000   D56          S         Beesley                  Mr. Lawrence                                       Mr              1\n",
       "12           1         1       Bonnell, Miss. Elizabeth                                  female  58.00  0      0      113783             26.5500   C103         S         Bonnell                  Miss. Elizabeth                                    Miss            1\n",
       "270          1         1       Bissette, Miss. Amelia                                    female  35.00  0      0      PC 17760           135.6333  C99          S         Bissette                 Miss. Amelia                                       Miss            1\n",
       "276          1         1       Andrews, Miss. Kornelia Theodosia                         female  63.00  1      0      13502              77.9583   D7           S         Andrews                  Miss. Kornelia Theodosia                           Miss            1\n",
       "306          1         1       Allison, Master. Hudson Trevor                            male    0.92   1      2      113781             151.5500  C22 C26      S         Allison                  Master. Hudson Trevor                              Master          1\n",
       "430          1         3       Pickard, Mr. Berk (Berk Trembisky)                        male    32.00  0      0      SOTON/O.Q. 392078  8.0500    E10          S         Pickard                  Mr. Berk (Berk Trembisky)                          Mr              1\n",
       "487          1         1       Hoyt, Mrs. Frederick Maxfield (Jane Anne Forby)           female  35.00  1      0      19943              90.0000   C93          S         Hoyt                     Mrs. Frederick Maxfield (Jane Anne Forby)          Mrs             1\n",
       "461          1         1       Anderson, Mr. Harry                                       male    48.00  0      0      19952              26.5500   E12          S         Anderson                 Mr. Harry                                          Mr              1\n",
       "450          1         1       Peuchen, Major. Arthur Godfrey                            male    52.00  0      0      113786             30.5000   C104         S         Peuchen                  Major. Arthur Godfrey                              Major           1\n",
       "446          1         1       Dodge, Master. Washington                                 male    4.00   0      2      33638              81.8583   A34          S         Dodge                    Master. Washington                                 Master          1\n",
       "436          1         1       Carter, Miss. Lucile Polk                                 female  14.00  1      2      113760             120.0000  B96 B98      S         Carter                   Miss. Lucile Polk                                  Miss            1\n",
       "431          1         1       Bjornstrom-Steffansson, Mr. Mauritz Hakan                 male    28.00  0      0      110564             26.5500   C52          S         Bjornstrom-Steffansson   Mr. Mauritz Hakan                                  Mr              1\n",
       "395          1         3       Sandstrom, Mrs. Hjalmar (Agnes Charlotta Bengtsson)       female  24.00  0      2      PP 9549            16.7000   G6           S         Sandstrom                Mrs. Hjalmar (Agnes Charlotta Bengtsson)           Mrs             1\n",
       "319          1         1       Wick, Miss. Mary Natalie                                  female  31.00  0      2      36928              164.8667  C7           S         Wick                     Miss. Mary Natalie                                 Miss            1\n",
       "391          1         1       Carter, Mr. William Ernest                                male    36.00  1      2      113760             120.0000  B96 B98      S         Carter                   Mr. William Ernest                                 Mr              1\n",
       "357          1         1       Bowerman, Miss. Elsie Edith                               female  22.00  0      1      113505             55.0000   E33          S         Bowerman                 Miss. Elsie Edith                                  Miss            1\n",
       "346          1         2       Brown, Miss. Amelia \"Mildred\"                             female  24.00  0      0      248733             13.0000   F33          S         Brown                    Miss. Amelia \"Mildred\"                             Miss            1\n",
       "342          1         1       Fortune, Miss. Alice Elizabeth                            female  24.00  3      2      19950              263.0000  C23 C25 C27  S         Fortune                  Miss. Alice Elizabeth                              Miss            1\n",
       "341          1         2       Navratil, Master. Edmond Roger                            male    2.00   1      1      230080             26.0000   F2           S         Navratil                 Master. Edmond Roger                               Master          1\n",
       "328          1         2       Ball, Mrs. (Ada E Hall)                                   female  36.00  0      0      28551              13.0000   D            S         Ball                     Mrs. (Ada E Hall)                                  Mrs             1\n",
       "888          1         1       Graham, Miss. Margaret Edith                              female  19.00  0      0      112053             30.0000   B42          S         Graham                   Miss. Margaret Edith                               Miss            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "train_df[(train_df['Survived'] == 1) & (train_df['Embarked'] == \"S\")]\n",
    "#survived_males['Pclass'].value_counts()\n",
    "#pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Male', 'is_Officer', 'is_Mr', 'is_Miss', 'is_Mrs', 'is_Master',\n",
      "       'is_Royalty', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1',\n",
      "       'Pclass_2', 'Pclass_3', 'FamilySize', 'FarePerPerson'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Male</th>\n",
       "      <th>is_Officer</th>\n",
       "      <th>is_Mr</th>\n",
       "      <th>is_Miss</th>\n",
       "      <th>is_Mrs</th>\n",
       "      <th>is_Master</th>\n",
       "      <th>is_Royalty</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>FarePerPerson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  Male  is_Officer  is_Mr  is_Miss  is_Mrs  is_Master  \\\n",
       "179  36.000000  True       False   True    False   False      False   \n",
       "263  40.000000  True       False   True    False   False      False   \n",
       "271  25.000000  True       False   True    False   False      False   \n",
       "277  29.642093  True       False   True    False   False      False   \n",
       "302  19.000000  True       False   True    False   False      False   \n",
       "413  29.642093  True       False   True    False   False      False   \n",
       "466  29.642093  True       False   True    False   False      False   \n",
       "481  29.642093  True       False   True    False   False      False   \n",
       "597  49.000000  True       False   True    False   False      False   \n",
       "633  29.642093  True       False   True    False   False      False   \n",
       "674  29.642093  True       False   True    False   False      False   \n",
       "732  29.642093  True       False   True    False   False      False   \n",
       "806  39.000000  True       False   True    False   False      False   \n",
       "815  29.642093  True       False   True    False   False      False   \n",
       "822  38.000000  True       False  False    False   False      False   \n",
       "\n",
       "     is_Royalty  Embarked_C  Embarked_Q  Embarked_S  Pclass_1  Pclass_2  \\\n",
       "179       False       False       False        True     False     False   \n",
       "263       False       False       False        True      True     False   \n",
       "271       False       False       False        True     False     False   \n",
       "277       False       False       False        True     False      True   \n",
       "302       False       False       False        True     False     False   \n",
       "413       False       False       False        True     False      True   \n",
       "466       False       False       False        True     False      True   \n",
       "481       False       False       False        True     False      True   \n",
       "597       False       False       False        True     False     False   \n",
       "633       False       False       False        True      True     False   \n",
       "674       False       False       False        True     False      True   \n",
       "732       False       False       False        True     False      True   \n",
       "806       False       False       False        True      True     False   \n",
       "815       False       False       False        True      True     False   \n",
       "822        True       False       False        True      True     False   \n",
       "\n",
       "     Pclass_3  FamilySize  FarePerPerson  \n",
       "179      True           0            0.0  \n",
       "263     False           0            0.0  \n",
       "271      True           0            0.0  \n",
       "277     False           0            0.0  \n",
       "302      True           0            0.0  \n",
       "413     False           0            0.0  \n",
       "466     False           0            0.0  \n",
       "481     False           0            0.0  \n",
       "597      True           0            0.0  \n",
       "633     False           0            0.0  \n",
       "674     False           0            0.0  \n",
       "732     False           0            0.0  \n",
       "806     False           0            0.0  \n",
       "815     False           0            0.0  \n",
       "822     False           0            0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_map = {\n",
    "    'Mr' :         'Mr',\n",
    "    'Mme':         'Mrs',\n",
    "    'Ms':          'Mrs',\n",
    "    'Mrs' :        'Mrs',\n",
    "    'Master' :     'Master',\n",
    "    'Mlle':        'Miss',\n",
    "    'Miss' :       'Miss',\n",
    "    'Capt':        'Officer',\n",
    "    'Col':         'Officer',\n",
    "    'Major':       'Officer',\n",
    "    'Dr':          'Officer',\n",
    "    'Rev':         'Officer',\n",
    "    'Jonkheer':    'Royalty',\n",
    "    'Don':         'Royalty',\n",
    "    'Sir' :        'Royalty',\n",
    "    'Countess':    'Royalty',\n",
    "    'Dona':        'Royalty',\n",
    "    'Lady' :       'Royalty'\n",
    "}\n",
    "\n",
    "class DataPreprocessor():\n",
    "    def __init__(self) -> None:\n",
    "        self.col_index_set = False\n",
    "        pass\n",
    "\n",
    "    def extract_title(self, names):\n",
    "        '''Extracts the title from the passenger names.'''\n",
    "\n",
    "        return names.str.extract(' ([A-Za-z]+)\\.', expand=False).map(titles_map)\n",
    "\n",
    "    def preprocess_dataset(self, df, test=False):\n",
    "        in_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Age', 'Embarked', 'Fare']\n",
    "        out_features = ['Survived']\n",
    "\n",
    "        #train_df['Title'] = train_df['Name'].map(lambda x: x.split(',')[1].split('.')[0])\n",
    "        \n",
    "        in_df = df.dropna(subset=[\"Embarked\"])\n",
    "        if not test:\n",
    "            out_y = in_df[out_features]\n",
    "        in_df = in_df[in_features]\n",
    "        in_df.loc[in_df[\"Age\"].isnull(), \"Age\"] = in_df[\"Age\"].mean()\n",
    "        in_df.loc[in_df[\"Fare\"].isnull(), \"Fare\"] = in_df[\"Fare\"].mean()\n",
    "        in_df['Male'] = in_df['Sex'].map(lambda x: True if x==\"male\" else False)\n",
    "        in_df['Title'] = self.extract_title(df['Name'])    \n",
    "\n",
    "        titles = set(titles_map.values())\n",
    "        for title in titles:\n",
    "            in_df['is_' + title] = in_df['Title'].map(lambda x: True if x==title else False)\n",
    "\n",
    "        for embarked in ['C', 'Q', 'S']:\n",
    "            in_df['Embarked_' + embarked] = in_df['Embarked'].map(lambda x: True if x==embarked else False)\n",
    "\n",
    "        for Pclass in [1, 2, 3]:\n",
    "            in_df['Pclass_' + str(Pclass)] = in_df['Pclass'].map(lambda x: True if x==Pclass else False)\n",
    "\n",
    "        in_df['FamilySize'] = in_df['SibSp'] + in_df['Parch']\n",
    "        in_df['FarePerPerson'] = in_df['Fare'] / (1 + in_df['FamilySize'])\n",
    "\n",
    "        in_df.drop(columns=\"Title\", inplace=True)\n",
    "        in_df.drop(columns=\"Embarked\", inplace=True)\n",
    "        in_df.drop(columns=\"Sex\", inplace=True)\n",
    "        in_df.drop(columns=\"Parch\", inplace=True)\n",
    "        in_df.drop(columns=\"SibSp\", inplace=True)\n",
    "        in_df.drop(columns=\"Fare\", inplace=True)\n",
    "        in_df.drop(columns=\"Pclass\", inplace=True)\n",
    "\n",
    "        if self.col_index_set:\n",
    "            in_df = in_df.reindex(columns = self.train_dumm_cols, fill_value = False)\n",
    "        else:\n",
    "            in_df = pd.get_dummies(in_df)\n",
    "            self.train_dumm_cols = in_df.columns\n",
    "            self.col_index_set = True\n",
    "\n",
    "        if test:            \n",
    "            return in_df\n",
    "        \n",
    "        return in_df, out_y\n",
    "\n",
    "t_proc = DataPreprocessor()\n",
    "x, y = t_proc.preprocess_dataset(train_df)\n",
    "x.head(3)\n",
    "print(t_proc.train_dumm_cols)\n",
    "z = t_proc.preprocess_dataset(test_df, test=True)\n",
    "z.head()\n",
    "x[x['FarePerPerson'] == 0]\n",
    "#z[\"Title_Royalty\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def kDataSplit(k, i, data):\n",
    "    val_ratio = 1.0 / k\n",
    "    interval = len(data) * val_ratio\n",
    "    interval = np.floor(interval).astype(np.int16)\n",
    "\n",
    "    splits = []\n",
    "    pool = np.array(range(len(data)))\n",
    "    for j in range(int(1/val_ratio)):\n",
    "        split = np.random.choice(pool, size=interval, replace=False)\n",
    "        split = split.tolist()\n",
    "        splits.append(split)\n",
    "        pool = pool[np.isin(pool, split, invert=True)]\n",
    "    #for j in range(len(splits)):\n",
    "    #    print(len(splits[j]))\n",
    "\n",
    "    #K-fold Cross-Validation    \n",
    "    val_pool = splits[i]\n",
    "    train_pool = []\n",
    "    for j in range(len(splits)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        train_pool.append(splits[j])\n",
    "    train_pool = np.hstack(train_pool).tolist()\n",
    "\n",
    "    train_data = data.iloc(axis=0)[train_pool]\n",
    "    val_data = data.iloc(axis=0)[val_pool]\n",
    "    return train_data, val_data\n",
    "\n",
    "def kCrossVal(k, model_class, model_params, data, preprocessor):\n",
    "    model = model_class(**model_params)\n",
    "\n",
    "    sum_score = 0.0\n",
    "\n",
    "    for i in range(k):\n",
    "        train_data, val_data = kDataSplit(k, i, data)\n",
    "        \n",
    "        X_train, y_train = preprocessor.preprocess_dataset(train_data)\n",
    "        X_val, y_val = preprocessor.preprocess_dataset(val_data)\n",
    "\n",
    "        model.fit(X_train, np.ravel(y_train))\n",
    "        val_pred = model.predict(X_val)\n",
    "        acc = accuracy_score(y_true=y_val, y_pred=val_pred)\n",
    "        sum_score += acc\n",
    "    return sum_score / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def tune_model(df, n_trials, mlflow_exp_name, preprocessor):\n",
    "    mlflow.set_experiment(mlflow_exp_name)\n",
    "    experiment = mlflow.get_experiment_by_name(mlflow_exp_name)\n",
    "\n",
    "    def objective(trial):  \n",
    "        run = client.create_run(experiment.experiment_id)\n",
    "\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 5),\n",
    "            \"random_state\": 1,\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 7),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "        }\n",
    "        for key in params:\n",
    "            client.log_param(run.info.run_id, key, params[key])\n",
    "\n",
    "        acc = kCrossVal(k=5,\n",
    "                        model_class=RandomForestClassifier,\n",
    "                        model_params=params,\n",
    "                        data=df, \n",
    "                        preprocessor=preprocessor)\n",
    "\n",
    "        client.log_metric(run.info.run_id, \"accuracy\", acc)\n",
    "        return acc\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=-1)\n",
    "    return study.best_trial.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/09/15 18:54:09 INFO mlflow.tracking.fluent: Experiment with name 'titanic-hyp-ee4907f1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomislav/mambaforge-pypy3/envs/titanic_env/lib/python3.11/site-packages/mlflow/data/digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  string_columns = trimmed_df.columns[(df.applymap(type) == str).all(0)]\n",
      "/home/tomislav/mambaforge-pypy3/envs/titanic_env/lib/python3.11/site-packages/mlflow/data/pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  return _infer_schema(self._df)\n",
      "/home/tomislav/mambaforge-pypy3/envs/titanic_env/lib/python3.11/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n",
      "/home/tomislav/mambaforge-pypy3/envs/titanic_env/lib/python3.11/site-packages/mlflow/models/signature.py:213: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  outputs = _infer_schema(model_output) if model_output is not None else None\n",
      "/home/tomislav/mambaforge-pypy3/envs/titanic_env/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/tomislav/mambaforge-pypy3/envs/titanic_env/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8214858064553361\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "mlflow_exp_name = \"titanic-hyp-\" + str(uuid.uuid4()).split(\"-\")[0]\n",
    "preprocessor = DataPreprocessor()\n",
    "X_train, y_train = preprocessor.preprocess_dataset(train_df)\n",
    "best_params = tune_model(train_df, \n",
    "                         n_trials=100, \n",
    "                         mlflow_exp_name=mlflow_exp_name, \n",
    "                         preprocessor=preprocessor)\n",
    "\n",
    "mlflow.set_experiment(\"titanic\")\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "with mlflow.start_run(run_name='rf_baseline'):\n",
    "    mlflow.set_tag(\"model_name\", \"RF\")    \n",
    "\n",
    "    model = RandomForestClassifier(**best_params)\n",
    "    param = model.get_params()\n",
    "    \n",
    "    model.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    acc = kCrossVal(k = 5, \n",
    "                    model_class = RandomForestClassifier, \n",
    "                    model_params = param, \n",
    "                    data = train_df,\n",
    "                    preprocessor=preprocessor)\n",
    "\n",
    "    joined_train = pd.concat((X_train,y_train),axis=1)\n",
    "    mlflow_train_dataset: PandasDataset = mlflow.data.from_pandas(joined_train)\n",
    "    mlflow.log_input(mlflow_train_dataset, context=\"training\")\n",
    "    mlflow.log_params(params=param)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    signature = infer_signature(model_input=X_train, model_output=y_train)\n",
    "    mlflow.sklearn.log_model(model, \"sk_models\", signature=signature)\n",
    "\n",
    "    print(acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New submission same as old? False\n",
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "import filecmp\n",
    "old_submission = '../kaggle/titanic/submission1.csv'\n",
    "new_submission = '../kaggle/titanic/submission.csv'\n",
    "\n",
    "if os.path.exists(new_submission):\n",
    "    os.remove(new_submission)\n",
    "\n",
    "logged_model = 'runs:/aae4c28c0a3d42b689e2f859aba5d77e/sk_models'\n",
    "\n",
    "ml_model = mlflow.sklearn.load_model(logged_model)\n",
    "\n",
    "X_test = preprocessor.preprocess_dataset(test_df, test=True)\n",
    "\n",
    "predictions = ml_model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_df.PassengerId,\n",
    "                       'Survived': predictions})\n",
    "output.to_csv(new_submission, index=False)\n",
    "\n",
    "is_diff = filecmp.cmp(old_submission, new_submission, shallow=False)\n",
    "\n",
    "print(\"New submission same as old? \" + str(is_diff))\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "X_test = preprocessor.preprocess_dataset(test_df, test=True)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_df.PassengerId,\n",
    "                       'Survived': predictions})\n",
    "output.to_csv('../kaggle/titanic/submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
